<?xml version="1.0" encoding="UTF-8"?>
<doc>
<chapter title="Introduction" label="ChapterIntroduction">
<quote>
The study of Expression is difficult, owing to the movements being often extremely slight, and of a fleeting nature.<br/>
Charles Darwin <cite ref='Darwin2002'/>
</quote>

<p><ac full='yes'>NVC</ac> comprises all forms of intentional, inter-personal communication apart from word based messages and is essential to understand communicated meaning in social situations <cite ref='Knapp2009'/> (see Figures <ref label='FigureManualGestureNvc'/> and <ref label='FigureGazeNvc'/> for illustrative examples) <footnote>This definition, together with the alternative perspective of <ac>NVC</ac>  that is independent of intentionality is further discussed in Section <ref label='ChapterLiteratureReview'/>. However, this is a good working definition.</footnote>. To enable new ways of intuitively interacting with computers, it would be beneficial for these devices to understand human communication, including <ac>NVC</ac> e.g. using innate communication skills to interact with computer characters. However, this is challenging because human behaviour expression and perception depends on many factors. This thesis describes a study based on the recording and culturally specific <footnote>“culturally specific” refers to the annotation data being collected from distinct cultural groups of annotators. In this study, the expressors of <ac>NVC</ac> were not divided into distinct cultural groups.</footnote> annotation of videos of informal spontaneous conversations, and develops techniques to successfully recognise meaningful communication based on visual non-verbal signals. The use of culturally specific, <macro v='continuous'/> labels based on dimensional annotations allows techniques to more faithfully model the culturally specific <ac>NVC</ac> perception of the human observers. “Continuous value”, in this case meaning “having an infinite number of possible values” rather than in the sense of “continuous recognition” meaning “providing a series of predictions based on a temporal series of observations”. <footnote>This is discussed further in Section <ref label='SectionDescribeQuestions'/>.</footnote> This results in an approach that can recognise <ac>NVC</ac> signals which is a step towards a system that can be used via common and intuitive communication skills. The four <ac>NVC</ac> signals selected for study were <i>agree, understand, thinking</i> and <i>question</i>. This thesis addresses two questions: <i>how can facial <ac>NVC</ac> signals be automatically recognised, given cultural differences in <ac>NVC</ac> perception?</i> and, <i>what do automatic recognition methods tell us about facial behaviour during informal conversations?</i></p>

<figure label="FigureManualGestureNvc" short="Hand gestures and facial expressions are often used to convey &lt;ac&gt;NVC&lt;/ac&gt;." caption="Hand gestures and facial expressions are often used to convey &lt;ac&gt;NVC&lt;/ac&gt;. The left photograph shows a woman waving goodbye and smiling. The right photograph depicts two armed security guards with their hands held in a blocking fashion while maintaining eye contact. Photographs used by permission (see Appendix &lt;ref label='AppendixPhotoPermissions'/&gt;).">
<graphic>introduction/wavegoodbye3420075962_ebae9c3a90_o.jpg</graphic>
<graphic>introduction/security2347593532_a4f7fe8250_b.jpg</graphic>
</figure>

<section short="Motivation: Why Attempt Automatic Recognition?" title="Motivation: Why Attempt Automatic Recognition of &lt;ac&gt;NVC&lt;/ac&gt;?">

<p>Computers are becoming pervasively used in society because of their portability, connectivity and low cost. They are being integrated into many common home appliances, including cars, mobile phones and televisions. <ac>NVC</ac> is a communication skill that almost all humans possess and may be used to operate computers if the appropriate interfaces are available. Furthermore, if human to human communication can be understood by a device, it may be possible for it to support or analyse the interaction <cite ref='Nakatsu98'/>. Existing <ac>HCI</ac> interfaces do not necessarily extend to multiple embedded computers, and particularly to those without traditional physical input controls <cite ref='Pantic2008'/>. Potential applications of automatic <ac>NVC</ac> recognition and emotionally aware computing include:</p>

<ul>
<li>Computer generated characters and robots capable of a fully interactive conversation, including perception and expression of <ac>NVC</ac> and emotion <cite ref='Pantic2009'/>. Early prototypes of this concept include the {SEMAINE} Sensitive Artificial Listener <cite ref='Schroder2011'/> and Asimo the robotic museum guide <cite ref='Asimo2013'/>. The computer character could be used for entertainment, companionship or for providing information and assistance.</li>
<li>Monitoring of social human behaviour and automatically providing services which are useful and appropriate for the social context. This could be in the form of advice, information or assistance <cite ref='Liao2006'/>. Computer may be able to optimise work patterns and reduce untimely interruptions <cite ref='Horvitz2003'/>. Emotionally aware computers may also provide an opportunity to practice social skills <cite ref='Hopkins2011'/>.</li>
<li>Computer based learning can detect if a human is confused or bored and adapt the teaching style accordingly <cite ref='DMello2007'/>.</li>
<li>Human operator monitoring in safety critical situations can detect tiredness, confusion or ignoring important information. This can be applied to transportation (cars <cite ref='Ji2004'/>, aircraft, etc.), industrial machinery or any safety critical device.</li>
<li>Text entry based on audio-visual speech recognition. Because of the association between words, emotions and <ac>NVC</ac> <cite ref='Cowie1999, Jones99'/>, a hybrid recognition approach could improve speech recognition performance.</li>
<li>Automatic labelling of broadcast material, based on the behaviour of the people featured in the footage, or from the reaction of observers <cite ref='Pantic2009b'/>.</li>
</ul>

<p>Applications of automatic <ac>NVC</ac> and behaviour recognition systems, in which the result is directly interpreted by humans include:</p>

<ul>
<li>Product evaluation. As a person interacts with a product, their reactions, emotions, mental state and intentions can be automatically recognised which provides useful information for evaluating a product's appeal <cite ref='Mano1993'/>.</li>
<li>Security applications. Behaviour monitoring <cite ref='Pfister2011'/>, covert lip reading <cite ref='Ong2011'/> and lie detection can be used by police for crime detection. The work contained in this thesis originated from the EPSRC LILiR project, which developed video based lip reading technology.</li>
<li>Human behaviour research. Higher level patterns in behaviour can be quickly analysed if low level <ac>NVC</ac> behaviour can be automatically recognised <cite ref='Okwechime2011'/>.</li>
</ul>

<p>Automatic <ac>NVC</ac> recognition has a wide range of potential applications but these are often in roles that are quite different from existing computer systems. If human behaviour is to be automatically recognised, the issue of context and situational dependence of human behaviour must be considered.</p>

</section>
<section title="From the Laboratory to the World (or Why Automatic &lt;ac&gt;NVC&lt;/ac&gt; Recognition is Difficult)" label="BackgroundWhyIsNvcDifficult" label2="BackgroundNaturalConvesationContainsRapidHeadMotion">

<figure short="Eye contact has a significant role in &lt;ac&gt;NVC&lt;/ac&gt;." caption="Eye contact has a significant role in &lt;ac&gt;NVC&lt;/ac&gt;. The left photograph shows a mother and child during mutual eye contact. The proximity and body pose of the people implies a close intimacy. The right photograph shows a man winking, which is often intended as a sign of trust. Photographs used by permission (see Appendix &lt;ref label='AppendixPhotoPermissions'/&gt;)." label="FigureGazeNvc">
<graphic>introduction/eyecontact2503079623_0a4aecf3c9_b.jpg</graphic>
<graphic>introduction/wink3083102723_2180fe13c6_b.jpg</graphic>
</figure>

<p>The way <ac>NVC</ac> is expressed and perceived depends on the context in which it is used e.g. certain types of behaviours may be considered as inappropriate in specific social situations and not be expressed, as well as behaviour such as nodding, winking, kissing, nodding, etc. that are interpreted depending on the social relationship <footnote>This is discussed more fully in Section <ref label='BackgroundWhatFactorsInfluenceNvc'/>.</footnote>. Many studies of automatic human behaviour recognition use posed data recorded in a laboratory environment <cite ref='Pantic2009, GaticaPerez2009, Vinciarelli2008'/>. Posed <ac>NVC</ac> data differs significantly from natural data. These differences include the types of communication actions used, expression intensity, the style of expression and in the timings of gestures. To maximise the range of applications in which the automatic system can be applied, this thesis attempts to use spontaneous human behaviour where possible.</p>

<p>At the time this work was conducted, there were limited available public data sets that would support the research. Data sets have been recorded in many different social situations with different degrees of spontaneity and naturalness. The most viable existing candidate was the AMI meeting corpus <cite ref='Carletta2007'/> (discussed in detail in Section <ref label='SectionExistingDataSets'/> along with other relevant data sets). However, only a portion of this corpus is naturalistic and it was not suitable for the tracking method employed in Chapter <ref label='ChapterClassification'/> and subsequent chapters. A new dataset that was suitable for this study was created. This thesis attempts to use a specific social context because behaviour is expression and perception is dependent on social context. A context was chosen that may have useful applications i.e. it is a commonly experienced situation that is important for interpersonal relationships. Also, the selected social situation should be easily reproducible in order to reduce resources requirements and to enable future work in the same social context. However, database recording and annotation is a challenging task due to the sensitivity of humans to context, practical considerations when recording usable video and audio, and the resource requirements for annotation <cite ref='Cowie2005'/>. A new corpus was recorded based on informal conversations between two people. This corpus was publicly released to assist further research.</p>

<p>Context is significant in determining the way people perceive <ac>NVC</ac> <cite ref='Hoque2009'/>. One significant contextual factor is culture <cite ref='Matsumoto08'/>; different cultures often have unique meaningful gestures <cite ref='Matsumoto2006'/>. If a single group of annotators is used and the ratings of annotators combined to form a group specific consensus label, these perceptual cultural differences would be ignored. Using annotators from a single culture results in annotations based on perceptions that are specific to that culture. An alternative would be to use independent sets of expressors and annotations, each set from the same culture. This would allow studies to identify <ac>NVC</ac> signals specific to that culture. However, the creation of such a dataset is beyond the scope of this thesis which focuses on cultural perception differences. To account for the cultural differences in perception, observers from three different cultures were used to create <macro v='culturallySpecific'/> annotations. This can be used as a basis for training and testing automatic recognition systems that are better suited to recognise <ac>NVC</ac> in a way that is more like a human observer. This is shown by confirming the presence of cultural differences in the annotation data <footnote>see Table <ref label='MeanAnnotatorCorrelationTable'/></footnote> and the automatic system trained on a specific culture is better at recognising <ac>NVC</ac> signals <footnote>see Table <ref label='CrossCulturePerformanceTable'/></footnote>.</p>

<p>Automatic recognition of <ac>NVC</ac> is difficult because there are many possible ways of expressing a particular <ac>NVC</ac>. Each person has a particular style of expression <cite ref='Buck1979'/>, as well as being influenced by many contextual factors. During most social situations, there are multiple sources of body and face motion that do not relate to <ac>NVC</ac>, including lip movement caused by speaking, ambient motion (small body movements that are continuously present, e.g. breathing) and the subset of emotions which are not involved in <ac>NVC</ac>. As Krauss <macro v='etal'/> <cite ref='Krauss1996'/> said “All hand gestures are hand movements, but not all hand movements are gestures[...]”.  <ac>NVC</ac> signals are expressed with a duration ranging from a fraction of a second to several hours <cite ref='Aaron1997, Verduyn2009'/>. <ac>NVC</ac> also involves visual, audio, tactile and other signals to convey messages <cite ref='Knapp2009'/>. It can be difficult to encode all this information in a form that is suitable for machine learning. This makes the learning of associations between gestures and <ac>NVC</ac> meaning very challenging. This thesis focuses on visual information in the human face. These visual signals are rich in <ac>NVC</ac> information but considering the face exclusively is far from being a comprehensive view of <ac>NVC</ac>.</p>

</section>
<section title="Main Thesis Contributions">

<p>To address these challenges, the main contributions of this thesis are:</p>

<ul>
<li>The design and publication of a new corpus to study human behaviour in an informal social situation. Minimal constraints on participants were imposed to allow spontaneous, natural conversation, which is necessary to gather data that is suitable to study <ac>NVC</ac>. The corpus is publicly available for further use <footnote>http://www.ee.surrey.ac.uk/Projects/LILiR/twotalk_corpus/</footnote> <cite ref='SheermanChase2009'/>. This database differs from previously available datasets (discussed in Section <ref label='SectionExistingDataSets'/>).</li>
<li>A crowd-sourced method for multi-cultural annotation. This provides a basis for studying automatic <ac>NVC</ac> recognition from different cultural perceptions. The labels used for annotation were based on <ac>NVC</ac> message meaning. Cultural differences in <ac>NVC</ac> perception were found to be present.</li>
<li>Design and evaluation of an automatic system for <ac>NVC</ac> meaning recognition. Various feature extraction methods and classifiers were compared to find an effective approach. <ac>NVC</ac> recognition was also approached from a regression perspective to produce <macro v='continuous'/> label predictions. Effective performance was observed using a system based on tracking facial features, computing distances between pairs of trackers, then forming features based on their statistical properties as the basis for regression. Feature selection was also employed and found to significantly improve performance. Using an automatic system trained on <macro v='culturallySpecific'/> annotation data was found to result in a higher performance than using annotations from a different culture.</li>
<li>Automatic techniques that were developed as part of the recognition system were applied to automatically identify patterns of human behaviour. The presence of interpersonal coordination in human behaviour was confirmed and quantified for the face. The feature components that were most relevant for <ac>NVC</ac> recognition were identified. Analysis was performed using both quantitative methods and by direct visualisation of facial regions involved.</li>
</ul>

<p>The outcomes of the thesis are:</p>

<ul>
<li>a new, publicly available <ac>NVC</ac> corpus that has been annotated by people from different cultures,</li>
<li>provided additional evidence that there are cultural differences in <ac>NVC</ac> perception, </li>
<li>an effective method for natural <ac>NVC</ac> recognition and</li>
<li>demonstration that culturally specific <ac>NVC</ac> recognition models leads to higher performance.</li>
</ul>

</section>
<section title="Overview of Thesis">

<p>Chapter <ref label='ChapterLiteratureReview'/> discusses existing research relating to <ac>NVC</ac>, classification, machine learning and <macro v='featureGeneration.'/> The recording of the <ac>NVC</ac> corpus is discussed in Chapter <ref label='ChapterCorpus'/>. This corpus is then used as a basis for studying automatic classification, as described in Chapter <ref label='ChapterClassification'/>. Chapter <ref label='ChapterBackchannel'/> investigates the effect of interpersonal coordination of behaviour between the two conversation participants, and attempts to use the reaction of a person to infer the <ac>NVC</ac> of an unseen subject. Collection of annotation data from culturally distinct groups is described in Chapter <ref label='ChapterAnnotation'/>. This annotation data is used in a study of a culturally specialised regression as discussed in Chapter <ref label='ChapterNvcRegression'/>. The facial deformation is encoded using a geometry based feature extraction method but this feature contains redundant and irrelevant information. Chapter <ref label='ChapterFeatureSelection'/> uses feature selection to isolate a set of features that improves <ac>NVC</ac> regression performance. General conclusions are drawn in Chapter <ref label='ChapterConclusion'/>.</p>
</section>
</chapter>
</doc>
