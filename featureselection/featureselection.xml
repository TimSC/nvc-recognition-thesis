<?xml version="1.0" encoding="UTF-8"?>
<doc>
<chapter title="Feature Selection for NVC Regression" label="ChapterFeatureSelection">

<quote>
Simplicity is the ultimate sophistication.<br/>
Leonardo da Vinci
</quote>

<p>The features used in the two previous chapters were extracted based on distances between pairs of tracker positions. These features encoded local deformations of the face, with each feature component corresponding to a specific, local area. 
Expression of emotions or <ac>NVC</ac> signals only involve part of the face but the features also encode areas of the face that are not involved in a specific <ac>NVC</ac> expression. Therefore, the feature data contains irrelevant information. Redundant information is also present in the algorithmic features, with tracker motions in a local area of the face often being closely coupled. Training based on features that are largely irrelevant leads to over-fitting, in which the <ac>NVC</ac> model is based on noise or incorrect features, rather than modelling the true underlying pattern. This results in poor generalisation and poor performance. This can be addressed by various means, including <macro v='featureGeneration'/> that is focused on the task at hand, or by feature selection.</p>

<p>Feature selection is the process of determining the relevance of features for a <ac>ML</ac> task. Using a smaller subset of relevant features reduces the computational complexity of <ac>ML</ac>. As the relevance of each feature is computed, this can give an insight to how <ac>NVC</ac> is expressed. Feature selection provides a way to find associations between <ac>NVC</ac> signals, relevant feature components and the associated areas of the face. Feature selection is a broad discipline with many approaches.
Features are either assigned a relevance weight or a subset of relevant features is found. This chapter uses an existing wrapper based approach which determines which subset of features is relevant. The selected feature subset can then be applied to <ac>NVC</ac> recognition and the performance change can be evaluated.</p>

<p>An <ac>NVC</ac> signal specific feature selection is computed for each culture. The performance contribution of each feature component is also evaluated. This results in a set of feature relevance weights for each <ac>NVC</ac> signal. The feature weights can be visualised to show the involvement of facial areas in the expression of <ac>NVC</ac> in an intuitive manner. This is based on segmenting a face using Voronoi tessellation around the position of trackers. Voronoi tessellation segments an image into cells based around seed positions; each point in the space is assigned to a cell based on the nearest seed position. This visualisation can either be used to check if the relevant facial areas conform to our expectation, or provide an indication as to the areas used by the automatic system. This in turn may provide clues as to human <ac>NVC</ac> perception, although facial areas used in human perception of emotion may differ from an automatic approach.</p>

<p>The main contributions of this chapter are:</p>

<ul>
 <li> A method of feature selection to select subset of features that are relevant for <ac>NVC</ac> recognition.</li>
 <li> A method of visualisation of the relevant features that is easy and intuitive to interpret.</li>
</ul>

<p>The next section provides an overview of relevant existing research. Section <ref label='SectionSbeFeatureSelection'/> discusses feature selection for the purposes of improving performance.</p>

<section title="Related Research">

<p>There are many approaches to feature selection, which vary in performance, computational cost and restrictions on the type of input data. There are three general types of feature selection (see Saeys <macro v='etal'/> for a review <cite ref='Saeys2007'/>):</p>

<ul>
 <li> filter methods, that consider feature components either individually or in groups, but do not consider the <ac>ML</ac> method used to make the final prediction. This scales to large sets of features. These methods do not consider effect of the <ac>ML</ac> method and may ignore the effects of combining groups of features.</li>
 <li> wrapper methods, that consider sets of features in conjunction with an <ac>ML</ac> method. They do consider groups of features in context with <ac>ML</ac> but they tend to be computationally intensive, they are classifier specific and are prone to over fitting.</li>
 <li> embedded methods, which are combined with <ac>ML</ac> methods to select features. This makes the feature selection methodology and results specific to the <ac>ML</ac> method used.</li>
</ul>

<p>Existing papers that use feature selection for facial analysis will now be discussed. The use of an embedded feature selection, such as a boosting classifier, can be used to weight a set of features based on relevance. This feature subset can then be used by a second, more sophisticated classifier. This approach was used by Valstar <cite ref='Valstar2006'/> to select shape features by Gentleboost, and Petridis and Pantic <cite ref='Petridis2008'/> used Adaboost to select relevant audio and visual features. However, performing feature selection in this way, assumes there is similarity in the optimal set of features for both methods, which might not be the case. Yang <macro v='etal'/> <cite ref='Yang2009'/> propose a feature selection method based on rough set theory on audio visual features. This avoids discretisation of feature values, as required by Adaboost, which may result in a loss of information. Filter based feature selection appears to have been largely avoided, probably because the number of feature components in the original feature vector is relatively low (usually thousands of feature components at most), and the interaction between features is often significant for emotion and <ac>NVC</ac> recognition.</p>

<p>Wrapper based methods include randomised feature selection approaches such as simulated annealing and genetic approaches, but these have not been popular in facial analysis. Deterministic wrapper based approaches have been applied to emotion recognition: Grimm <cite ref='Grimm2007'/> used <ac>SFS</ac> to isolate relevant audio features. This method begins with an empty set and incrementally adds features that produce the greatest performance increase, in a greedy fashion. An alternative, called <ac full='yes'>SBE</ac>, is to start with a full set of features and incrementally eliminate features that result in the best performance <cite ref='Kittler1978'/>. The <ac>SBE</ac> approach was used by el Kaliouby and Robinson <cite ref='ElKaliouby2004'/> to find the most relevant geometric features.</p>

<p>There are several existing papers that identify which features have been selected for emotion or <ac>NVC</ac> recognition, but it is less common to attempt to visualise which features have been selected. If features are shown, they are often visualised individually (e.g. <cite ref='Yang2009'/>), which can make comprehension of the overall distribution difficult. In experimental psychology, gaze patterns in perception have been visualised <cite ref='Jack2009'/>. Busso and Narayanan visualised areas of the face that were correlated with prosodic and vocal tract features for different emotions <cite ref='Busso2007'/>. It would be beneficial to have a method that is similar to these approaches for visualisation of feature selection results in a way that can be intuitively understood. </p>

</section>
<section title="&lt;acs&gt;SBE&lt;/acs&gt; Feature Selection}" label="SectionSbeFeatureSelection">

<p>The approach used is a greedy <ac>SBE</ac> of the features <cite ref='Kittler1978'/>. This section describes the method in detail and the resulting performance impact. 
Backward searching was thought to be preferable to forward searching because the interaction of features can be found and exploited. Forward search, particularly in the first few iterations, adds features without the benefit of other complimentary features. In contrast, a backward search allows irrelevant features to be eliminated while retaining features that contain complementary information. Also, it is possible to accelerate the backward search by removing more than one feature at each iteration, which reduces the computational cost.
Some feature component subsets are more effective than others. Unfortunately, <ac>SBE</ac> may not find a globally optimal feature subset. If all possible feature subsets are considered as a space, <ac>SBE</ac> performs a gradient descent to minimise error. </p>

<subsection title="Method">

<p>Feature selection occurs within a person independent, cross validation framework. There are eight folds in cross validation, resulting in eight different partitionings of seen and unseen data sets. Feature selection is applied to the seen data of a specific cross validation fold, to determine a relevant feature subset. <ac>SVR</ac> is then applied to the feature subset to produce a model suitable for prediction.</p>

<algorithm language="Python" caption="Features are selected by a greedy backward elimination, beginning with a feature set that contains all possible features. The feature set at each stage is stored for later use. The algorithm is expressed as Python 2.7 code. The function &lt;i&gt;EvaluateRemainingFeatures&lt;/i&gt; is defined in Algorithm &lt;ref label='AlgFeaturesToRemove'/&gt;." label="AlgFeatureSelectOverview">
def PerformFeatureSelection(data, labels):

   #The current mask begins with every feature enabled
   currentMask = np.ones((data.shape[1]), dtype=np.bool)

   #For storing the intermediate steps during feature selection
   allMasks = []

   #While more than one feature remains in the current mask
   while currentMask.sum() > 1:

      #Evaluate which features to remove
      toRemove = EvaluateRemainingFeatures(currentMask, data, labels)

      #Update the current mask and remove features
      for featToRemove in toRemove:
         currentMask[featToRemove[1]] = False

      #Store mask for later analysis
      allMasks.append(currentMask)

   return allMasks
</algorithm>

<p>The procedure for &lt;acs&gt;SBE&lt;/acs&gt; is shown in Algorithm <ref label='AlgFeatureSelectOverview'/>.
The search begins with a current set $<macro v='currentFeatureSet'/> = \{1...<macro v='numFeatures'/>\}$ which is initialised to include all possible feature components. The components to be removed from $<macro v='currentFeatureSet'/>$ at each iteration is then determined. The current set $<macro v='currentFeatureSet'/>$ is then updated and the process continues until the current set $<macro v='currentFeatureSet'/>$ is empty. For the large number of components, it is too time consuming to remove components at a rate of 1 per iteration. To accelerate the process, multiple feature components are removed nearer the start of the <ac>SBE</ac> process. As the number of components in the current set approaches zero, the rate of feature elimination returns to the standard 1 feature component per iteration. This produces a significant speed increase, but risks the removal of non-optimal components and this may result in a sub-optimal final feature set. The number of feature components removed from the current feature set at each iteration is denoted $<macro v='numToRemoveInMask'/>$. This depends on the number of feature components $<macro v='numFeaturesInMask'/>$ in the current set $<macro v='currentFeatureSet'/>$ as follows:</p>

eqn\begin{gather}
eqn\label{EquationNumFeaturesToRemove}
eqn\numToRemoveInMask = \begin{cases}
eqn200 : \numFeaturesInMask > 1000 \\
eqn100 : \numFeaturesInMask > 400, \numFeaturesInMask \le 1000 \\
eqn1 : \numFeaturesInMask \le 400
eqn\end{cases}
eqn\end{gather}

<p>These thresholds were based on an intuitive expectation that only a small subset of features are required for accurate recognition.</p>

<algorithm caption="Each feature in the current feature set is tested. The features that cause the best performance are retained and the features that worsen performance are preferred for removal. The function &lt;i&gt;TestPerf&lt;/i&gt; is defined in Algorithm &lt;ref label='AlgTestSingleFeature'/&gt;." label="AlgFeaturesToRemove">
def EvaluateRemainingFeatures(mask, data, labels):

   #Determine how many components to remove, based on the mask
   numToRemove = CalcNumToRemove(mask.sum()) 

   #Initalise an empty list, based on the number of components in the mask
   scores = [None for count in range(mask.sum())] 

   #For each remaining component in the mask
   for count, featNum in enumerate(np.where(mask == True)[0]):

      #Create a test mask with a single component disabled
      testMask = np.copy(currentMask)
      testMask[featNum] = False

      #Evaluate the perfomance of the test mask and store the score
      scores[count] = (TestPerf(data[:, testMask], labels), featNum)

   #Return a list of features to remove
   scores.sort()
   scores.reverse()
   return scores[:numToRemove]
</algorithm>

<p>To find an appropriate subset of features for removal from the current feature set, the contribution of each feature component needs to be assessed. An overview of this process is shown in Algorithm <ref label='AlgFeaturesToRemove'/>.
Each feature component in the current feature set $<macro v='currentFeatureSet'/>$ is selected as the test component and the performance impact of the removal of the component is evaluated. The features are then prioritised, with the feature components resulting in the lowest performance preferred for removal. This process becomes progressively faster as the current feature set becomes smaller.</p>

<algorithm caption="Testing the performance of a test set of feature components. The regression can use any suitable method, but in this study $&lt;macro v='nu'/&gt;$-SVR is used." label="AlgTestSingleFeature">
def TestPerf(maskedData, labels):

   #Prepare cross validation sets
   kf = cross_validation.KFold(len(maskedData), numFolds)

   #Create an empty list for predictions
   allPredictions = [] 
   allLabels = []

   for train, test in kf: #For each cross validation fold

      #Fit a regression model on the training data
      regressor.fit(maskedData[train,:], labels[train])

      #Store the predictions based on the test data
      allPredictions.extend(regressor.predict(maskedData[test,:])) 

      #Store the test labels in this fold
      allLabels.extend(labels[test]) 

   #Calculate the overall correlation of predictions and test labels
   return np.corrcoef(allPredictions, allLabels)[0,1]
</algorithm>

<p>To test a specific feature component, regression models are trained and tested to assess the performance of the remaining feature components as shown in Algorithm <ref label='AlgTestSingleFeature'/>.
A temporary set $<macro v='tempFeatureSet'/>$ is created which creates a copy of the current set $<macro v='currentFeatureSet'/>$ except for the removal of the test component $i$:</p>

eqn\begin{gather}
eqn\tempFeatureSet = \{j: j \in \currentFeatureSet, j \ne i\}
eqn\end{gather}

<p>The feature data is split into cross validation folds. These “feature selection” folds are distinct from the “system” cross validation folds discussed earlier, so that each fold contains data from multiple human subjects.</p>

<p>This produces a series of sets $\{<macro v='currentFeatureSet'/>^<macro v='numFeatures..'/><macro v='currentFeatureSet'/>^1\}$ that correspond to each stage in the progressive removal of features. Each set contains a different number of feature components. The performance of the feature set on the unseen data can then be determined. The expectation is for an increase in performance as poor features are removed. As the <ac>SBE</ac> process is nearing termination, some features that are critical to <ac>NVC</ac> regression are removed and the performance sharply declines. The performance of the feature subset at each stage is evaluated and retained for later analysis.</p>

<p>Because this process results in multiple sets which are used to create multiple <ac>NVC</ac> models, it is not obvious which feature set to use and how many feature components are optimal. Simply selecting the peak performance when evaluating feature sets on unseen data violates the separation of seen and unseen data. For simplicity, this section uses the feature set $<macro v='currentFeatureSet'/>^{unseen}$ having the peak performance for unseen test data to determine the number of feature components. It is likely that different <ac>NVC</ac> signals require a specific set of geometric features to be effective. Therefore, feature selection is computed for a specific <ac>NVC</ac> category and using a specific culture's annotation data. The processing of test set $<macro v='tempFeatureSet'/>$ has been parallelized in this implementation, resulting in a speed increase. The next section uses the set $<macro v='currentFeatureSet'/>^{seen}$ having the highest performance on seen training data only.</p>

</subsection>
<subsection title="Results" label="SectionFeatureSelectionUnseenPeak">

<figure label="FigureShuffleGbrThink" short="The performance of the system progressively improves as backward feature selection eliminates poor features." caption="The performance of the system progressively improves as backward feature selection eliminates poor features. The upper line shows the seen data, which is used in the feature selection algorithm. The lower line shows the performance of the unseen data. The unseen data corresponds to subject 3008.">
<graphic width="0.7">featureselection/shuffle-gbr-think/shufflefs-reverse-GBR-thinking-3008.pdf</graphic>
</figure>

<p>A typical plot of performance against the number of feature components in the subset is shown in Figure <ref label='FigureShuffleGbrThink'/>. As expected, the performance of predicting unseen test data increases as features are removed until performance suffers a sharp decline. The far left starting point of the lower curve corresponds to the performance of the system discussed in the previous chapter (i.e. without feature selection). In this example, feature selection results in a significant increase in performance. A feature set containing between 10 to 275 features encompasses the highest performance, with the peak performance requiring only 10 features. This feature set is smaller than the terse $<macro v='frameFeature'/>_{geometric-h}$ features (Section <ref label='SectionGenerateHeuristic'/>). However, it is unlikely that this feature set will be effective for other non-<i>thinking</i> <ac>NVC</ac> regression. This can be a disadvantage because the <ac>SBE</ac> method is <ac>NVC</ac> category specific and a great deal of computation is required to retrain the system for a different <ac>NVC</ac> signal.</p>

<p>The feature selection curves are relatively linear until approximately 400 features remain. This corresponds to the threshold in Equation <ref label='EquationNumFeaturesToRemove'/>. The change in the curve behaviour at this point suggests that a different set of thresholds might result in a higher peak, although this was not investigated.</p>

<figure label="FigureShuffleFeatureSelect" short="Additional examples of performance increases as feature selection progresses." caption="Additional examples of performance increases as feature selection progresses. The left plot shows GBR &lt;i&gt;question&lt;/i&gt; performance. The right plot shows KEN &lt;i&gt;agree&lt;/i&gt; performance. Both unseen data folds correspond to subject 1011.">
<graphic width="0.49">featureselection/shuffle-gbr-think/shufflefs-reverse-GBR-question-1011.pdf</graphic>
<graphic width="0.49">featureselection/shuffle-gbr-think/shufflefs-reverse-KEN-agree-1011.pdf</graphic>
</figure>

<p>This pattern is repeated for most other <ac>NVC</ac> categories and in different cultures. While almost every test fold subject benefits from the feature selection process, not all system cross validation folds yield the same level of performance increase. The left plot of Figure <ref label='FigureShuffleFeatureSelect'/> shows an instance in which feature selection was not effective. The performance is low before feature selection begins, which might indicate a problem with the approach in recognizing this subject performing <i>question</i> <ac>NVC</ac> signals. The right curve shows typical feature selection behaviour in a different culture (KEN in this case). A typical gradual improvement in performance can be seen, as features are removed before a sharp decline.</p>

<table short="System performance with termination of features selection based on the peak of unseen performance." caption="System performance with termination of features selection based on the peak of unseen performance. This violates the separation of training and test data but this shows the performance with an ideal termination point." label="TableShuffledFoldsTerminationOnUnseenCheat">
<tr><td>Area </td><td> NVC      </td><td> Terminate </td></tr>
<tr><td>     </td><td> Category </td><td> By Unseen </td></tr>
<tr><td>     </td><td>          </td><td> Peak </td></tr>
<tr><td>GBR </td><td> Agree </td><td> 0.588 </td></tr>
<tr><td>GBR </td><td> Question </td><td> 0.453 </td></tr>
<tr><td>GBR </td><td> Thinking </td><td> 0.617 </td></tr>
<tr><td>GBR </td><td> Understand </td><td> 0.640 </td></tr>
<tr><td>IND </td><td> Agree </td><td> 0.627 </td></tr>
<tr><td>IND </td><td> Question </td><td> 0.534 </td></tr>
<tr><td>IND </td><td> Thinking </td><td> 0.638 </td></tr>
<tr><td>IND </td><td> Understand </td><td> 0.647 </td></tr>
<tr><td>KEN </td><td> Agree </td><td> 0.648 </td></tr>
<tr><td>KEN </td><td> Question </td><td> 0.453 </td></tr>
<tr><td>KEN </td><td> Thinking </td><td> 0.654 </td></tr>
<tr><td>KEN </td><td> Understand </td><td> 0.636 </td></tr>
<tr><td>All </td><td> Average </td><td> 0.586 </td></tr>
</table>

<p>The optimal number of features is not known before feature selection begins. 
The peak of unseen performance is 10 features, while the peak for seen performance is at approximately 125 features (see Figure <ref label='FigureShuffleGbrThink'/>). A simple approach to determine the optimal number of features is to use the peak performance of unseen data. The performance for this method is shown in Table <ref label='TableShuffledFoldsTerminationOnUnseenCheat'/>. However, this method violates the separation of training and unseen test data. Therefore, the results should not be directly compared to performance results in the previous chapter. The table shows the performance with the ideal termination of feature selection. This table implies that if terminated at an appropriate point, <ac>SBE</ac> can result in a significant performance gain. </p>

</subsection>
<subsection title="Terminate &lt;acs&gt;SBE&lt;/acs&gt; Based on Seen Training Data" label="SectionFeatureSelectionSeenPeak">

<table short="Comparison of various approaches of termination of the feature selection process, along with the performance without feature selection from the previous chapter." caption="Comparison of various approaches of termination of the feature selection process, along with the performance without feature selection from the previous chapter. Termination using the unseen peak, as discussed in Section &lt;ref label='SectionFeatureSelectionUnseenPeak'/&gt;, is the upper limit for performance based on &lt;ac&gt;SBE&lt;/ac&gt;. Termination based on peak seen performance (highlighted) is discussed in Section &lt;ref label='SectionFeatureSelectionSeenPeak'/&gt;." label="TableShuffledFoldsTerminationOnSeenComparison">
<tr><td>Area </td><td> NVC       </td><td> Terminate </td><td highlight="yes"> Terminate </td><td> Without  </td></tr>
<tr><td>     </td><td> Category  </td><td> By Unseen </td><td highlight="yes"> By Seen   </td><td> Feature </td></tr>
<tr><td>     </td><td>           </td><td> Peak      </td><td highlight="yes"> Peak      </td><td> Selection </td></tr>
<tr><td>GBR </td><td> Agree      </td><td> 0.588 </td><td highlight="yes"> 0.523 </td><td> 0.340 </td></tr>
<tr><td>GBR </td><td> Question   </td><td> 0.453 </td><td highlight="yes"> 0.385 </td><td> 0.188 </td></tr>
<tr><td>GBR </td><td> Thinking   </td><td> 0.617 </td><td highlight="yes"> 0.556 </td><td> 0.440 </td></tr>
<tr><td>GBR </td><td> Understand </td><td> 0.640 </td><td highlight="yes"> 0.605 </td><td> 0.389 </td></tr>
<tr><td>IND </td><td> Agree      </td><td> 0.637 </td><td highlight="yes"> 0.600 </td><td> 0.400 </td></tr>
<tr><td>IND </td><td> Question   </td><td> 0.534 </td><td highlight="yes"> 0.458 </td><td> 0.236 </td></tr>
<tr><td>IND </td><td> Thinking   </td><td> 0.638 </td><td highlight="yes"> 0.588 </td><td> 0.363 </td></tr>
<tr><td>IND </td><td> Understand </td><td> 0.547 </td><td highlight="yes"> 0.498 </td><td> 0.257 </td></tr>
<tr><td>KEN </td><td> Agree      </td><td> 0.648 </td><td highlight="yes"> 0.604 </td><td> 0.462 </td></tr>
<tr><td>KEN </td><td> Question   </td><td> 0.453 </td><td highlight="yes"> 0.358 </td><td> 0.162 </td></tr>
<tr><td>KEN </td><td> Thinking   </td><td> 0.654 </td><td highlight="yes"> 0.600 </td><td> 0.363 </td></tr>
<tr><td>KEN </td><td> Understand </td><td> 0.636 </td><td highlight="yes"> 0.595 </td><td> 0.431 </td></tr>
<tr><td>All </td><td> Average    </td><td> 0.586 </td><td highlight="yes"> 0.531 </td><td> 0.336 </td></tr>
</table>

<p>The number of features for termination of the feature selection process should be determined based on seen training data. This restriction represents a system which is less reliant on manual tuning of parameters. The peak training data performance can be used to determine when to terminate the feature selection process. This is likely to select a non-optimal number of features, but this approach respects seen and unseen data separation. The results may be compared to the regression system in the previous chapter. The performance of this method is shown in the highlighted column of Table <ref label='TableShuffledFoldsTerminationOnSeenComparison'/>. Feature selection produces a large increase in performance over the method described in the previous chapter. Therefore, feature selection is beneficial for <i>geometric-a</i> features because it removes irrelevant features and results in a feature subset that is more suited for the specific <ac>NVC</ac>. The next section changes the feature selection folds to be person independent, rather than multi-person.</p>

</subsection>
<subsection title="Terminate &lt;acs&gt;SBE&lt;acs&gt; on Person-Independent Folds" caption="SectionPersonIndependentFeatureSelection">

<p>Feature selection in this chapter uses multiple folds to determine the performance as features are eliminated (Algorithm <ref label='AlgTestSingleFeature'/>). Previously, each fold contained multi-person data in which every subject in the seen data was present in each feature selection fold. This does not affect the overall system testing, which remains person independent throughout. This change may be advantageous because feature elimination would be based on a system that had been trained and tested on different subjects and may improve the generalisation. However, as feature selection is run iteratively, the system may begin to over fit the training data.</p>

<table short="Performance of the system using person independent feature selection folds (highlighted, Section &lt;ref label='SectionPersonIndependentFeatureSelection'/&gt;), compared to feature selection on multi person folds (Section &lt;ref label='SectionFeatureSelectionSeenPeak'/&gt;)." capture="Performance of the system using person independent feature selection folds (highlighted, Section &lt;ref label='SectionPersonIndependentFeatureSelection'/&gt;), compared to feature selection on multi person folds (Section &lt;ref label='SectionFeatureSelectionSeenPeak'/&gt;). There is little overall difference in performance." label="TableFeatureSelectionPersonIndependent">
<tr><td>Area</td><td> NVC       </td><td highlight="yes">Person      </td><td> Multi- </td></tr>
<tr><td>    </td><td> Category  </td><td highlight="yes">Independent </td><td> Person </td></tr>
<tr><td>    </td><td> Category  </td><td highlight="yes">Folds       </td><td> Folds </td></tr>
<tr><td>GBR</td><td> Agree      </td><td highlight="yes">0.492 </td><td> 0.523</td></tr>
<tr><td>GBR</td><td> Question   </td><td highlight="yes">0.341 </td><td> 0.385</td></tr>
<tr><td>GBR</td><td> Thinking   </td><td highlight="yes">0.581 </td><td> 0.556</td></tr>
<tr><td>GBR</td><td> Understand </td><td highlight="yes">0.599 </td><td> 0.605</td></tr>
<tr><td>IND</td><td> Agree      </td><td highlight="yes">0.571 </td><td> 0.600</td></tr>
<tr><td>IND</td><td> Question   </td><td highlight="yes">0.522 </td><td> 0.458</td></tr>
<tr><td>IND</td><td> Thinking   </td><td highlight="yes">0.554 </td><td> 0.588</td></tr>
<tr><td>IND</td><td> Understand </td><td highlight="yes">0.487 </td><td> 0.498</td></tr>
<tr><td>KEN</td><td> Agree      </td><td highlight="yes">0.630 </td><td> 0.604</td></tr>
<tr><td>KEN</td><td> Question   </td><td highlight="yes">0.393 </td><td> 0.358</td></tr>
<tr><td>KEN</td><td> Thinking   </td><td highlight="yes">0.598 </td><td> 0.600</td></tr>
<tr><td>KEN</td><td> Understand </td><td highlight="yes">0.591 </td><td> 0.595</td></tr>
<tr><td>All</td><td> Average    </td><td highlight="yes">0.530 </td><td> 0.531</td></tr>
</table>

<p>The performance of termination based on person independent folds is shown in Table <ref label='TableFeatureSelectionPersonIndependent'/>. Although there are minor differences in performance for <ac>NVC</ac> categories, the overall performance is relatively unchanged. Using either of these methods, feature selection finds a subset of features that are specialised in recognition of a specific <ac>NVC</ac> signal. The next section provides a method for visualising the feature subset and an interpretation of the visualisations.</p>

</subsection>
</section>
<section title="Visualising Selected Feature Subsets" label="SectionVisualiseFeatureSelection">

<p>Each feature component in the feature selection subset corresponds to a pair of trackers. This provides information about which facial regions are used by the regression model for <ac>NVC</ac> recognition. It is useful to know which areas of the face are involved in <ac>NVC</ac> expression: to assist understanding of human behaviour and to develop effective feature extraction methods. 
In order to visualise areas of the face relevant to <ac>NVC</ac> expression, each feature component of the <i>geometric-a</i> feature is assigned a weight based on the contribution that the feature component makes to the performance. As feature component $i$ is removed at <ac>SBE</ac> iteration $j$, an increase $<macro v='weightSingleFeature'/>_j$ in performance from $<macro v='systemPerformance'/>_{j-1}$ to $<macro v='systemPerformance'/>_{j}$ where $(<macro v='systemPerformance'/>_{j} > <macro v='systemPerformance'/>_{j-1})$ indicates the component was detrimental and is ignored ($<macro v='weightSingleFeature'/> <macro v='in'/> <mathbb>R</mathbb>^{<macro v='numFeatures'/>}, <macro v='systemPerformance'/> <macro v='in'/> <mathbb>R</mathbb>^{<macro v='numFeatures'/>}$). If a component is removed and the performance drops, this indicates the component was relevant. </p>

eqn\begin{gather}
eqn\label{EquationWeightTracker}
eqn\weightSingleFeature_{j} = \begin{cases}
eqn|\systemPerformance_{j} - \systemPerformance_{j-1}| : \systemPerformance_{j} - \systemPerformance_{j-1} > 0 \\
eqn0 : \systemPerformance_{j} - \systemPerformance_{j-1} \le 0
eqn\end{cases}
eqn\end{gather}

<p>The modulus of the performance drop $<macro v='weightSingleFeature'/>$ is added to the weight of the two trackers $<macro v='trackerWeight'/>^a_{j}$ and $<macro v='trackerWeight'/>^b_{j}$ that correspond to the component $i$ ($<macro v='trackerWeight'/> <macro v='in'/> <mathbb>R</mathbb>^{<macro v='numTrackers'/> <macro v='times'/> <macro v='numFeatures'/>}$). </p>

eqn\begin{gather}
eqn\trackerWeight^a_{j-1} = \trackerWeight^a_{j} + \weightSingleFeature_{j} \\
eqn\trackerWeight^b_{j-1} = \trackerWeight^b_{j} + \weightSingleFeature_{j} \\
eqn\end{gather}

<p>After the <ac>SBE</ac> process is run to completion, the tracker weights are normalised to form normalised weight $<macro v='trackerWeightNorm'/>$ which makes the tracker maximum weight equal to one ($<macro v='trackerWeightNorm'/> <macro v='in'/> <mathbb>R</mathbb>^{<macro v='numTrackers'/>}$).</p>

eqn\begin{gather}
eqn\trackerWeightNorm^x = \frac{\trackerWeight^x_{j=0}}{max(\trackerWeight)}
eqn\end{gather}

<figure label="FigureRigidTrackers" short="Manual division of tracker points into a flexible and rigid sets." caption="Manual division of tracker points into a flexible and rigid sets. Flexible points are shown in green. Rigid points are shown in cyan. Humans have relatively little ability to move these rigid facial points relative to the skull.">
<graphic width="0.49">featureselection/TrackerPositions.pdf</graphic>
</figure>

<figure short="Bar charts showing the normalised weights of tracking features for the four &lt;ac&gt;NVC&lt;/ac&gt; categories." caption="Bar charts showing the normalised weights of tracking features for the four &lt;ac&gt;NVC&lt;/ac&gt; categories. Rigid and non-rigid trackers are shown as different colours, which indicate the relative importance of expression vs. head pose in recognition. The tracker ID numbers correspond to the numbering in Figure &lt;ref label='FigureRigidTrackers'/&gt;. Results are from GBR culture, with person independent folds in feature selection. Visualisation areas have been averaged across test folds." lable="FigureFeatureWeightBarCharts">
Agree, Question <br/>
<graphic width="0.49">featureselection/baragree.pdf</graphic>
<graphic width="0.49">featureselection/barquestion.pdf</graphic><br/>
<graphic width="0.49">featureselection/barthinking.pdf</graphic>
<graphic width="0.49">featureselection/barunderstand.pdf</graphic><br/>
Thinking, Understand
</figure>

<p>To investigate the relative importance of head pose when compared to the role expression, the trackers have been manually divided into rigid and non-rigid facial points. The manual division of trackers is shown in Figure <ref label='FigureRigidTrackers'/>. However, it is possible to automatically separate points into rigid and flexible sets, as described by Del Bue <macro v='etal'/> <cite ref='DelBue2005'/>. The normalised tracker weights for each of the four <ac>NVC</ac> categories are shown in Figure <ref label='FigureFeatureWeightBarCharts'/>. All <ac>NVC</ac> categories have significant weights assigned to trackers on flexible parts of the face, which implies expression is significant for <ac>NVC</ac> recognition. The weights assigned to rigid trackers are relatively low for <i>question</i> <ac>NVC</ac> and to some extent in <i>thinking</i>. This suggests that these <ac>NVC</ac> signals are largely conveyed by expression, with head pose having little importance. In contrast, the rigid tracker weights have higher weights in <i>agree</i>, which suggests that head pose has a role in the automatic recognition process. This confirms our expectation that agreement is often expressed by the nodding of the head. The weightings also show that the trackers that have low weightings for all of the studied <ac>NVC</ac> signals. The lowest weighted tracker overall was number 22, which corresponds to a part of the eyebrow. This may indicate a problem with this tracker or this area is redundant for recognizing these types of <ac>NVC</ac> signals.</p>

<p>Although each tracker weight corresponds to a specific area of the face, it is difficult to form an overall impression of which areas of the face are involved, based on these bar charts. A better approach is to visualise the relevant areas in relation to an actual face. However, the visualisation process is complicated by the head pose. 
Head pose changes are not localised to an specific area of the face and should be removed. The head pose is generally encoded by the distance between two rigid points on the face. Facial deformations can either be encoded by distances which are either between rigid to flexible facial points or between flexible to flexible facial points.
The remaining non-rigid points correspond to the flexible regions of the face and are responsible for facial deformations. The facial areas are based on a Voronoi tessellation of the face <cite ref='Dirichlet1850'/>, based on tracker positions on a manually selected frontal view of the face. The normalised weights of each tracked point are used to control the saturation of the local area in the image. Relevant areas are shown as normal saturation. Irrelevant areas are shown as desaturated, which makes the colour tend to pure white for low weights. This enables an intuitive way to visualise relevant areas for <ac>NVC</ac> expression around the face.</p>

<figure short="Visualising the areas of face used for &lt;macro v='featureGeneration'/&gt;" caption="Visualising the areas of face used for &lt;macro v='featureGeneration.'/&gt; The face is segmented based on Voronoi tessellation. More saturated areas indicate the importance of an area, less saturated areas are not relevant for a particular &lt;ac&gt;NVC&lt;/ac&gt;. Results are from GBR culture, with person independent folds in feature selection. Visualisation areas have been averaged across test folds." label="FigureFeatureSelectionVis">
Agree, Question <br/>
<graphic width="0.39">featureselection/visoutput-agree-crop-bng.png</graphic>
<graphic width="0.39">featureselection/visoutput-question-crop-bng.png</graphic><br/>
<graphic width="0.39">featureselection/visoutput-thinking-crop-bng.png</graphic>
<graphic width="0.39">featureselection/visoutput-understand-crop-bng.png</graphic><br/>
Thinking, Understand <br/>
</figure>

<p>The results of the visualisation are shown in Figure <ref label='FigureFeatureSelectionVis'/>. The clearest example of facial areas corresponding to our expectation is for <i>thinking</i>. The eyes are prominently selected and gaze is already thought to play a role in this <ac>NVC</ac>, as discussed in Section <ref label='SectionVisualisingGaze'/>. The other features provide an indication into less well understood <ac>NVC</ac>. The brow region seems important for <i>question</i> <ac>NVC</ac>. When intense examples of <i>question</i> are viewed, there is generally consistent brow lowering (action unit 4) lasting for less than a second which occurs at or near the end of a question sentence (see Figure <ref label='FigureBrowLoweringQuestion'/>). The feature selection seems to be using this behaviour as the basis for recognition. This connection between verbal questioning and brow lowering has not been previously reported in published research, although Ekman mentions unpublished experiments which found this association <cite ref='Ekman1979'/>. Brow raising and lowering has also been documented in sign language but in this context, the direction of raising or lowering has a distinct semantic meaning, depending on the type of question that is being asked <cite ref='Ekman1999'/>. For <i>agree</i> and <i>understand</i>, the areas selected are less specific but generally indicate that the eyes and mouth are involved and the brow area is not used. While the visualisation shows areas that are involved in <ac>NVC</ac> recognition by <ac>ML</ac>, it does not necessarily imply that humans use these areas for recognition, but shows that information is present in these areas. However, there is a strong possibility that humans also use this information during <ac>NVC</ac> perception.</p>

<figure label="FigureBrowLoweringQuestion" caption="Brow lowering (action unit 4), lasting for less than a second, often occurs at or near the end of a question sentence.">
<graphic width="0.49">featureselection/question-clip_1HTGE8FuGw.jpg</graphic>
<graphic width="0.49">featureselection/question-clip_4bg18VX1W3.jpg</graphic>
</figure>

<p>This approach could be improved by additional trackers, would would improve the spatial resolution of the visualisation.</p>

</section>
<section title="Applying Feature Selection to the Mind Reading Corpus" label="SectionMindReadingFeatureSelection">

<p>Classification of mental states in the Mind Reading corpus was previously discussed in Section <ref label='SectionMindReading'/>. This section applies feature selection to the algorithmic geometric features in an attempt to improve classification performance. The motivation is the save as in the case of TwoTalk: the feature vector contains irrelevant or redundant information which can reduce the performance of recognition. The experimental arrangement used is the same as described in Section <ref label='SectionMindReading'/>, except for only a subset of features are used, as determined by Algorithm <ref label='AlgFeatureSelectOverview'/>. Because cross validation evaluation is performed on a leave-one-clip-out basis, it is not computationally feasible to perform a separate feature selection for each of the 174 folds. In this case, feature selection is conducted on a two fold basis on the entire corpus. As the feature selection removes features by <ac>SBE</ac>, the performance based on two fold classification accuracy rises. The change in performance during the <ac>SBE</ac> process is shown in Figure <ref label='FigureMindReadingPerfFeatureSbe'/>. The resultant masks are then evaluated using the standard level-one-clip-out; the classification accuracy of this is shown in Figure <ref label='FigureMindReadingSbeTestPerf'/>. As usual, the performance gradually increases as unnecessary or detrimental features are removed, before a sudden reduction in performance. Peak performance for the feature selection occurs for between 50 and 90 feature components. A set of 88 feature components is manually selected, based on it having the best classification accuracy. The number of features removed at each stage is as follows:</p>

eqn\begin{gather}
eqn\label{EquationNumFeaturesToRemoveMindReading}
eqn\numToRemoveInMask = \begin{cases}
eqn4 : \numFeaturesInMask > 1000 \\
eqn2 : \numFeaturesInMask > 500, \numFeaturesInMask \le 1000 \\
eqn1 : \numFeaturesInMask \le 500
eqn\end{cases}
eqn\end{gather}

<p>This removes features more slowly than in the previous section, which should help prevent useful features being eliminated. However, this results in the system being evaluated at more stages during the <ac>SBE</ac> process.</p>

<figure caption="Classification accuracy of two-fold cross validation on the Mind Reading corpus as features are eliminated by &lt;ac&gt;SBE&lt;/ac&gt;." label="FigureMindReadingPerfFeatureSbe">
<graphic width="0.8">featureselection/mindreading-fs.pdf</graphic>
</figure>

<figure caption="Classification accuracy of level-one-clip-out cross validation on the Mind Reading corpus as features are eliminated by &lt;ac&gt;SBE&lt;/ac&gt;, based on the previously selected feature sets." label="FigureMindReadingSbeTestPerf">
<graphic width="0.8">featureselection/mindreading-test.pdf</graphic>
</figure>

<figure short="Performance of various classification methods based on the Mind Reading Corpus." caption="Performance of various classification methods based on the Mind Reading Corpus. Orange corresponds to algorithmic geometric features without feature selection (method described in Section &lt;ref label='SectionMindReading'/&gt;). Green corresponds to the algorithmic geometric feature selection method proposed in this section, with 88 components. Yellow corresponds to el Kaliouby and Robinson &lt;cite ref='ElKaliouby2004'/&gt;. Chance prediction performance is 17%." label="FigureMindReadingAlgFs">
<graphic width="0.8">featureselection/MindReadingFeatureSelectPerf.png</graphic>
</figure>

<table label="TableMindReadingAlgFs" short="Confusion matrix of mental state classification using geometric algorithmic features with feature selection on the Mind Reading corpus." caption="Confusion matrix of mental state classification using geometric algorithmic features with feature selection on the Mind Reading corpus. Feature selection resulted in a set of 88 feature components which are more effective at classification.">
<tr><td>mental state</td><td>agreeing</td><td>concentrating</td><td>disagreeing</td><td>interested</td><td>thinking</td><td>unsure</td><td>accuracy</td></tr>
<tr><td>agreeing	</td><td><b>20</b>	</td><td>0	</td><td>4	</td><td>2	</td><td>5	</td><td>5	</td><td>55.6%</td></tr>
<tr><td>concentrating	</td><td>0	</td><td><b>0</b>	</td><td>2	</td><td>7	</td><td>3	</td><td>6	</td><td>0.0%</td></tr>
<tr><td>disagreeing	</td><td>7	</td><td>0	</td><td><b>8</b>	</td><td>2	</td><td>3	</td><td>4	</td><td>33.3%</td></tr>
<tr><td>interested	</td><td>2	</td><td>2	</td><td>0	</td><td><b>20</b>	</td><td>2	</td><td>4	</td><td>66.7%</td></tr>
<tr><td>thinking	</td><td>5	</td><td>3	</td><td>2	</td><td>2	</td><td><b>21</b>	</td><td>3	</td><td>58.3%</td></tr>
<tr><td>unsure		</td><td>1	</td><td>2	</td><td>2	</td><td>2	</td><td>5	</td><td><b>18</b>	</td><td>60.0%</td></tr>
<tr><td>mean		</td><td>	</td><td>	</td><td>	</td><td>	</td><td>	</td><td>	</td><td><b>45.6</b>%</td></tr>
</table>

<p>The use of feature selection results in a significant performance increase but is still not as effective as el Kaliouby and Robinson <cite ref='ElKaliouby2004'/>. Classification for <i>concentrating</i> is worse than chance classification and is often mislabelled as <i>interested</i> or <i>unsure</i>, which are arguable closely related to <i>concentrating</i>. There are less examples of <i>concentrating</i> in the corpus, which may be a factor in poor recognition performance for this class. Other reasons for the lower performance include:</p>

<ul>
 <li> Acted behaviour is more intense and more consistent than spontaneous behaviour. This may be exploited by the temporal model used by el Kaliouby and Robinson to achieve a better result.</li>
 <li> <ac>NVC</ac> and mental states are different concepts. The proposed system was developed for <ac>NVC</ac> and el Kaliouby and Robinson's system was developed to address the Mind Reading corpus.</li>
 <li> There is less video data available for each class and more subjects in the Mind Reading corpus, which may affect which method is suitable. Specifically, the proposed method uses subject specific normalisation which can require a significant amount of data to reach a stable and robust model of facial behaviour.</li>
 <li> el Kaliouby and Robinson discarded video clips that were not tracked, while we consider all videos, which is a harder problem.</li>
 <li> The <macro v='featureGeneration'/> technique used by each method is different, which may encode relevant information that is missed by other <macro v='featureGeneration'/> approaches. Although the <i>geometric-h</i> heuristic features are based on el Kaliouby and Robinson, it is not the same. They use appearance features that focus on mouth opening and teeth visible, which may be useful in distinguishing some of the classes.</li>
 <li> Feature selection on geometric algorithmic features was conducted based on the performance of all classes. However, it may be more effective to have a one-vs-one class basis for feature selection, to better isolate features that distinguish each class.</li>
</ul>

</section>
<section title="Conclusion">

<p>Geometric features used in the previous chapter contain a great deal of redundant and irrelevant components. This chapter describes an <ac>SBE</ac> based method to find a subset of features that are relevant for a specific <ac>NVC</ac> signal. This removes feature components that are not relevant for <ac>NVC</ac> recognition and this results in a significant performance increase. The feature subset is then visualised to show the facial areas used by the automatic system. This provides evidence of which facial areas are involved in the expression of each <ac>NVC</ac> signal. Knowing the areas of the face used for <ac>NVC</ac> can suggest feature types that better encode these local areas, avoids computation of irrelevant or redundant features, as well as improving our understanding of human behaviour.</p>

<p>The areas of the face that are used by the system either correspond to the expected areas, or for <ac>NVC</ac> signals that are less well understood, they give an indication as to the facial areas that are involved. The areas used for each <ac>NVC</ac> are different, which implies that the feature selection has isolated feature components that are specific to each <ac>NVC</ac>. Thinking is known to involve gaze aversion and this is clearly seen in that feature components that encode eye movement are retained by the feature selection process. Based on reviewing corpus videos, it was manually observed that a sentence ending with a question is often accompanied by a brief brow lowering and this is also consistent with the visualisation of questioning <ac>NVC</ac>.</p>

<p><ac>SBE</ac> feature selection was based on multiple folds of the seen data. Using folds that were either person-independent or person-dependent did not make a significant performance difference. The termination of the <ac>SBE</ac> process was based on the peak performance of the training data used in the optimisation. This does not select the optimal number of features but it still resulted in a significant performance increase. If a system can be manually tuned, a slightly better performance can be achieved but the number of features that is optimal depends on the specific <ac>NVC</ac>.</p>

<p>The visualisation of the feature selection subsets used annotation data from a single culture. It may be possible to investigate whether other cultures use different areas of the face for <ac>NVC</ac> perception, based on feature selection. Gaze patterns are culturally dependent for emotion recognition <cite ref='Jack2009'/>. However, humans may be using different areas of the face for recognition, compared to an automatic system. This may be due to the feature extraction process not being as comprehensive as human perception. The areas used by an automatic system may provide indirect clues as to the way human perception operates. This cross cultural visualisation is not attempted in this thesis, because this would require a larger video corpus, more comprehensive facial encoding and additional annotation data to provide a reliable result.</p>

<p>Head pose has a role in <ac>NVC</ac> but the visualisation in this chapter is focused on local facial deformations. The features are only considered as simplistic temporal variations. The temporal encoding currently considers an entire clip, so cannot temporally localise relevant motion in <ac>NVC</ac> expression. However, with more detailed temporal encoding, which might consider variation in a sliding window, a particular time and area of the face could be identified as important for <ac>NVC</ac> automatic regression. The feature selection framework also might provide a framework to extend the existing automatic system to other feature types. Considering many different areas of the face (or holistic facial features) over multiple time scales and temporal offsets will result in a vast number of potential features. For this reason, techniques that are suitable for spotting patterns in large data sets, such as data mining, may be relevant to facial analysis.</p>

<p>The feature selection method presented here is a simple but computationally intensive approach. The removal of many features during the early iterations was necessary to make the approach practical but the performance implications of this approximation are not well understood. Other feature selection methods may be investigated to reduce the computation requirements and improve performance.</p>

</section>
</chapter>
</doc>

